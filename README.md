# AnÃ¡lise de Sentimentos com LSTM e RNN

Este projeto compara o desempenho de modelos de redes neurais recorrentes (RNN e LSTM) na tarefa de anÃ¡lise de sentimentos usando o dataset IMDB.

## ğŸ“Œ Objetivos

- Comparar a acurÃ¡cia e o tempo de treino entre modelos RNN e LSTM
- Analisar casos divergentes entre as previsÃµes dos modelos
- Avaliar o impacto de dois hiperparÃ¢metros no desempenho da LSTM:
  - NÃºmero de unidades na camada LSTM
  - Tamanho do vocabulÃ¡rio (nÃºmero de palavras consideradas)

## ğŸ§ª Experimentos

Experimentos com variaÃ§Ã£o de hiperparÃ¢metros mostram que:
- Menor nÃºmero de unidades (64) teve melhor desempenho
- VocabulÃ¡rio de 5000 palavras teve a maior acurÃ¡cia (0.8495)

## ğŸ“Š VisualizaÃ§Ãµes

Foi gerado um heatmap que mostra a relaÃ§Ã£o entre nÃºmero de unidades, vocabulÃ¡rio e acurÃ¡cia.

## ğŸ“ Estrutura

- `main.ipynb`: Notebook principal com todo o cÃ³digo de treino e avaliaÃ§Ã£o
- `requirements.txt`: DependÃªncias do projeto
- `README.md`: Este arquivo

## â–¶ï¸ ExecuÃ§Ã£o

```bash
pip install -r requirements.txt
